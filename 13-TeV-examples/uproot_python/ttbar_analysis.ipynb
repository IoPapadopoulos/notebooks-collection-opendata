{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cadbf1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import uproot  # For reading ROOT files efficiently\n",
    "\n",
    "import awkward as ak  # To represent nested data in columnar format\n",
    "import numpy as np  # For numerical calculations such as histogramming\n",
    "\n",
    "import matplotlib.pyplot as plt  # For creating plots and visualizations\n",
    "from matplotlib.ticker import AutoMinorLocator  # For adding minor ticks to plot axes\n",
    "\n",
    "import requests  # For making HTTP requests\n",
    "\n",
    "import time  # For timing operations and adding delays if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ed56dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Integrated luminosity in inverse femtobarns\n",
    "lumi = 10000.\n",
    "\n",
    "# Fraction of events to process (1 means all events)\n",
    "fraction = 1\n",
    "\n",
    "# Conversion factor from MeV to GeV\n",
    "MeV2GeV = 0.001\n",
    "\n",
    "# Initial weight factor\n",
    "weight = 1.\n",
    "\n",
    "# Minimum transverse momentum (pT) limit in GeV\n",
    "pt_lim = 30\n",
    "\n",
    "# MV2c10 b-tagging algorithm discriminant cut value\n",
    "MV2c10_lim = 0.828\n",
    "\n",
    "# Dictionary of samples to be processed\n",
    "samples = {\n",
    "    # Real data samples\n",
    "    'data': {'list' : ['data_A','data_B','data_C','data_D'],},\n",
    "    \n",
    "    # Main Monte Carlo (MC) sample: top quark pair production\n",
    "    'MC' : {  'list' : ['mc_410000.ttbar_lep'],},\n",
    "    \n",
    "    # Single top quark production samples\n",
    "    'Single top' : {  'list' : [\n",
    "        'mc_410011.single_top_tchan',      # t-channel single top\n",
    "        'mc_410012.single_antitop_tchan',  # t-channel single anti-top\n",
    "        'mc_410013.single_top_wtchan',     # Wt-channel single top\n",
    "        'mc_410014.single_antitop_wtchan', # Wt-channel single anti-top\n",
    "        'mc_410025.single_top_schan',      # s-channel single top\n",
    "        'mc_410026.single_antitop_schan'   # s-channel single anti-top\n",
    "        ],},\n",
    "    \n",
    "    # Diboson production samples\n",
    "    'Diboson' : {  'list' : [\n",
    "        'mc_363356.ZqqZll',    # Z(qq)Z(ll)\n",
    "        'mc_363358.WqqZll',    # W(qq)Z(ll)\n",
    "        'mc_363359.WpqqWmlv',  # W+(qq)W-(lv)\n",
    "        'mc_363360.WplvWmqq',  # W+(lv)W-(qq)\n",
    "        'mc_363359.WpqqWmlv',  # W+(qq)W-(lv)\n",
    "        'mc_363360.WplvWmqq',  # W+(lv)W-(qq)\n",
    "        'mc_363489.WlvZqq'     # W(lv)Z(qq)\n",
    "         ],},\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6166de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_weight(data):\n",
    "    # Calculate the common scale factor\n",
    "    scale = (data[\"scaleFactor_LepTRIGGER\"] * data[\"scaleFactor_PILEUP\"] * data[\"scaleFactor_BTAG\"] *\n",
    "             (data[\"mcWeight\"] / data[\"SumWeights\"]) * (data[\"XSection\"] * lumi))\n",
    "\n",
    "    # Calculate the scaleFactorE and scaleFactorM\n",
    "    scaleFactorE = data[\"scaleFactor_ELE\"] * scale\n",
    "    scaleFactorM = data[\"scaleFactor_MUON\"] * scale\n",
    "\n",
    "    # Create boolean masks based on conditions\n",
    "    e_condition = data[\"trigE\"] & (data[\"mcWeight\"] != 0.0)\n",
    "\n",
    "    # Use boolean masks to select relevant entries from scaleFactorE and scaleFactorM\n",
    "    weight_list = ak.where(e_condition, scaleFactorE, scaleFactorM)\n",
    "\n",
    "    return weight_list\n",
    "\n",
    "def cut_trig(trigE, trigM):\n",
    "    # Return True if either electron or muon trigger fired\n",
    "    return trigE | trigM\n",
    "\n",
    "def one_lep(lep_n):\n",
    "    # Return True if exactly one lepton in the event\n",
    "    return lep_n == 1\n",
    "\n",
    "def cut_lep_pt(lep_pt):\n",
    "    # Return True if lepton pT is above 30 GeV\n",
    "    return lep_pt * MeV2GeV >= pt_lim\n",
    "\n",
    "def cut_met_et(met_et):\n",
    "    # Return True if missing ET is above 30 GeV\n",
    "    return met_et * MeV2GeV >= 30\n",
    "\n",
    "def cut_W_mt(lep_pt, lep_phi, met_et, met_phi):\n",
    "    # Calculate W transverse mass and apply cut\n",
    "    Wmt_2 = 2 * lep_pt * met_et * (1 - np.cos(lep_phi - met_phi)) * MeV2GeV**2\n",
    "    Wmt = ak.where(Wmt_2 >= 0, np.sqrt(Wmt_2), np.NaN)\n",
    "    bool_list = Wmt >= 30\n",
    "    return [Wmt, bool_list]\n",
    "\n",
    "def cut_Njet_and_Nbjet(jet_pt, jet_MV2c10):\n",
    "    # Convert jet pT to GeV\n",
    "    jet_pt_GeV = jet_pt * MeV2GeV\n",
    "\n",
    "    # Count jets above pT threshold\n",
    "    num_pt = ak.sum(jet_pt_GeV >= pt_lim, axis=1)\n",
    "\n",
    "    # Count b-tagged jets\n",
    "    num_btag = ak.sum(jet_MV2c10 >= MV2c10_lim, axis=1)\n",
    "\n",
    "    # Require at least 4 jets and 2 b-tagged jets\n",
    "    bool_list = (num_pt >= 4) & (num_btag >= 2)\n",
    "\n",
    "    # Get pT of leading jet, if it exists\n",
    "    leading_pt_jets = ak.where(\n",
    "        bool_list & (ak.num(jet_pt_GeV) > 0),\n",
    "        ak.firsts(jet_pt_GeV, axis=1),\n",
    "        np.nan)\n",
    "\n",
    "    # Store number of jets and b-jets for events passing the cut\n",
    "    num_jets = ak.where(bool_list, num_pt, np.nan)\n",
    "    b_jets = ak.where(bool_list, num_btag, np.nan)\n",
    "\n",
    "    return [bool_list, num_jets, b_jets, leading_pt_jets]\n",
    "\n",
    "def mtop(jet_pt, jet_E, jet_eta, jet_phi, jet_MV2c10, lep_pt, lep_eta, lep_phi, lep_E, met_et, met_phi):\n",
    "    # This function calculates the mass of semileptonic decaying top quark and hadronic decay top quark \n",
    "\n",
    "    # Convert lepton kinematics to GeV\n",
    "    lep_E_GeV = lep_E * 1e-3\n",
    "    lep_pt_mag = lep_pt * 1e-3\n",
    "    lep_px = lep_pt_mag * np.cos(lep_phi)\n",
    "    lep_py = lep_pt_mag * np.sin(lep_phi)\n",
    "    lep_pz = lep_pt_mag / np.tan(2.0 * np.arctan( np.exp( -lep_eta ) ) )\n",
    "\n",
    "    # Convert MET to GeV and calculate its components\n",
    "    met_pt_mag = met_et * 1e-3\n",
    "    met_px = met_pt_mag * np.cos(met_phi)\n",
    "    met_py = met_pt_mag * np.sin(met_phi)\n",
    "\n",
    "    # Calculate neutrino pz solutions\n",
    "    # Calculate coefficient 'a' of the quadratic equation\n",
    "    a = 4 * (lep_E_GeV**2 - lep_pz**2)\n",
    "    \n",
    "    # Calculate coefficient 'b' of the quadratic equation, 6464.16 is (80.4 GeV)^2, which is the W boson mass squared\n",
    "    b = -4 * (6464.16 + ((lep_px + met_px)**2) + ((lep_py + met_py)**2) - (lep_E_GeV**2) - (met_pt_mag**2) + (lep_pz**2)) * lep_pz\n",
    "    \n",
    "    # Calculate coefficient 'c' \n",
    "    c = 4 * (lep_E_GeV**2) * (met_pt_mag**2) - (6464.16 + ((lep_px + met_px)**2) + ((lep_py + met_py)**2) - (lep_E_GeV**2) - (met_pt_mag**2) + (lep_pz**2))**2\n",
    "    \n",
    "    # Calculate the discriminant\n",
    "    Delta = b**2 - 4 * a * c\n",
    "    \n",
    "    # Calculate the two solutions for met_pz using the quadratic formula\n",
    "    # If Delta is negative, set the solution to NaN\n",
    "    met_pz1 = ak.where(Delta >= 0, (-b + np.sqrt(Delta)) / ( 2 * a), np.nan)\n",
    "    met_pz2 = ak.where(Delta >= 0, (-b - np.sqrt(Delta)) / ( 2 * a), np.nan)\n",
    "\n",
    "    # Calculate the two solutions for met_E\n",
    "    met_E_1 = np.sqrt(met_px**2 + met_py**2 + met_pz1**2)\n",
    "    met_E_2 = np.sqrt(met_px**2 + met_py**2 + met_pz2**2)\n",
    "\n",
    "    # Convert jet kinematics to GeV\n",
    "    Jet_E = jet_E * 1e-3\n",
    "    Jet_pt = jet_pt * 1e-3\n",
    "    px = Jet_pt * np.cos(jet_phi)\n",
    "    py = Jet_pt * np.sin(jet_phi)\n",
    "    pz = Jet_pt / np.tan(2.0 * np.arctan(np.exp(-jet_eta)))\n",
    "\n",
    "    # Identify b-tagged jets\n",
    "    b_tagged = jet_MV2c10 >= MV2c10_lim\n",
    "\n",
    "    # Separate b-tagged and non-b-tagged jets\n",
    "    b_tagged_px, b_tagged_py, b_tagged_pz, b_tagged_E = px[b_tagged], py[b_tagged], pz[b_tagged], Jet_E[b_tagged]\n",
    "    \n",
    "    b_tagged_eta, b_tagged_phi = jet_eta[b_tagged], jet_phi[b_tagged]\n",
    "    \n",
    "    non_b_px, non_b_py, non_b_pz, non_b_E = px[~b_tagged], py[~b_tagged], pz[~b_tagged], Jet_E[~b_tagged]\n",
    "    \n",
    "\n",
    "    # Calculate delta R between lepton and b-tagged jets\n",
    "    lep_eta_broadcasted, _ = ak.broadcast_arrays(ak.flatten(lep_eta), b_tagged_eta)\n",
    "    lep_phi_broadcasted, _ = ak.broadcast_arrays(ak.flatten(lep_phi), b_tagged_phi)\n",
    "    dR = np.sqrt((lep_eta_broadcasted - b_tagged_eta)**2 + (lep_phi_broadcasted - b_tagged_phi)**2)\n",
    "    \n",
    "    # Find indices of closest and farthest b-tagged jets to the lepton\n",
    "    max_dR_indices = ak.singletons(ak.argmax(dR, axis=1))\n",
    "    min_dR_indices = ak.singletons(ak.argmin(dR, axis=1))\n",
    "\n",
    "    # Extract kinematics of closest and farthest b-tagged jets\n",
    "    closest_b_jet_E, closest_b_jet_px = b_tagged_E[min_dR_indices], b_tagged_px[min_dR_indices]\n",
    "    closest_b_jet_py, closest_b_jet_pz = b_tagged_py[min_dR_indices], b_tagged_pz[min_dR_indices]\n",
    "    farthest_b_jet_E, farthest_b_jet_px = b_tagged_E[max_dR_indices], b_tagged_px[max_dR_indices]\n",
    "    farthest_b_jet_py, farthest_b_jet_pz = b_tagged_py[max_dR_indices], b_tagged_pz[max_dR_indices]\n",
    "\n",
    "    # Helper function to create combinations of jets\n",
    "    def combo(list1):\n",
    "        jets_pairs = ak.combinations(list1, 2, fields=['List1', 'List2'])\n",
    "        sum_List = jets_pairs['List1'] + jets_pairs['List2']\n",
    "        return sum_List\n",
    "\n",
    "    # Create combinations of non-b-tagged jets\n",
    "    com_non_b_px, com_non_b_py = combo(non_b_px), combo(non_b_py)\n",
    "    com_non_b_pz, com_non_b_E = combo(non_b_pz), combo(non_b_E)\n",
    "\n",
    "    # Calculate mass difference from W boson mass    \n",
    "    W_mass_2 = com_non_b_E**2 - (com_non_b_px**2 + com_non_b_py**2 + com_non_b_pz**2)\n",
    "    W_mass = ak.where(W_mass_2 >0, np.sqrt(W_mass_2), np.NaN)\n",
    "    com_DM_W = 80.4 - W_mass\n",
    "    abs_diff = np.abs(com_DM_W)\n",
    "\n",
    "    # Select jet pairs close to W mass           \n",
    "    check_abs = abs_diff <= 20\n",
    "    check_abs_array = ak.singletons(ak.any(check_abs, axis=1))\n",
    "\n",
    "    # Find best jet pair\n",
    "    min_diff_indices = ak.argmin(abs_diff, axis=1)\n",
    "    min_indices = ak.singletons(min_diff_indices)\n",
    "\n",
    "    # Extract kinematics of selected jet pair\n",
    "    sel_com_jet_E = com_non_b_E[min_indices]\n",
    "    sel_com_jet_px, sel_com_jet_py = com_non_b_px[min_indices], com_non_b_py[min_indices]\n",
    "    sel_com_jet_pz = com_non_b_pz[min_indices]\n",
    "\n",
    "    # Handle cases where no suitable jet pair is found\n",
    "    sel_com_jet_E = ak.without_parameters(ak.where(ak.num(sel_com_jet_E, axis=1) == 0, np.nan, sel_com_jet_E))\n",
    "    sel_com_jet_px = ak.without_parameters(ak.where(ak.num(sel_com_jet_px, axis=1) == 0, np.nan, sel_com_jet_px))\n",
    "    sel_com_jet_py = ak.without_parameters(ak.where(ak.num(sel_com_jet_py, axis=1) == 0, np.nan, sel_com_jet_py))\n",
    "    sel_com_jet_pz = ak.without_parameters(ak.where(ak.num(sel_com_jet_pz, axis=1) == 0, np.nan, sel_com_jet_pz))\n",
    "\n",
    "    # Calculate hadronic top mass\n",
    "    m_jjj = np.sqrt( (sel_com_jet_E + farthest_b_jet_E)**2 - (sel_com_jet_px + farthest_b_jet_px)**2 -    \n",
    "                     (sel_com_jet_py + farthest_b_jet_py)**2 - (sel_com_jet_pz + farthest_b_jet_pz)**2 )\n",
    "    \n",
    "    # Apply W mass constraint\n",
    "    m_jjj = ak.where(check_abs_array, m_jjj, np.nan).tolist()\n",
    "\n",
    "    # Calculate leptonic top mass for both neutrino pz solutions\n",
    "    m_lvb_1 = (lep_E_GeV + met_E_1 + closest_b_jet_E)**2 - ( (lep_px + met_px + closest_b_jet_px)**2 +\n",
    "     (lep_py + met_py + closest_b_jet_py)**2 + (lep_pz + met_pz1 + closest_b_jet_pz)**2 )\n",
    "\n",
    "    m_lvb_2 = (lep_E_GeV + met_E_2 + closest_b_jet_E)**2 - ( (lep_px + met_px + closest_b_jet_px)**2 +\n",
    "     (lep_py + met_py + closest_b_jet_py)**2 + (lep_pz + met_pz2 + closest_b_jet_pz)**2 )\n",
    "\n",
    "    # Handle complex masses\n",
    "    m_lvb_1 = ak.where(m_lvb_1 >= 0, np.sqrt(m_lvb_2), np.nan).tolist()\n",
    "    m_lvb_2 = ak.where(m_lvb_2 >= 0, np.sqrt(m_lvb_2), np.nan).tolist()\n",
    "\n",
    "    # Flatten and return results\n",
    "    m_jjj, m_lvb_1, m_lvb_2 = ak.flatten(m_jjj), ak.flatten(m_lvb_1), ak.flatten(m_lvb_2)\n",
    "    return [m_jjj, m_lvb_1, m_lvb_2]\n",
    "\n",
    "def read_file(path,sample,start_entry):\n",
    "    \"\"\"\n",
    "    Reads data from a file, applies cuts, and returns an awkward array.\n",
    "\n",
    "    Args:\n",
    "        path (str): Path to the file.\n",
    "        sample (str): Sample name.\n",
    "        start_entry (int): Starting entry for data retrieval.\n",
    "\n",
    "    Returns:\n",
    "        ak.Array: Concatenated awkward array containing events passing all cuts.\n",
    "    \"\"\"\n",
    "    start = time.time() # start the clock\n",
    "    print(\"\\tProcessing: \"+sample) # print which sample is being processed\n",
    "    data_all = [] # define empty list to hold all data for this sample\n",
    "\n",
    "    # Open the tree called \"mini\" using a context manager (will automatically close files/resources)\n",
    "    with uproot.open(f\"{path}:mini\") as tree:\n",
    "        numevents = tree.num_entries  # Number of events\n",
    "        for data in tree.iterate(\n",
    "            [\n",
    "                \"mcWeight\", \"scaleFactor_ELE\", \"scaleFactor_MUON\", \"scaleFactor_LepTRIGGER\",\n",
    "                \"scaleFactor_PILEUP\", \"scaleFactor_BTAG\", \"trigE\", \"trigM\", \"lep_n\", \"lep_pt\",\n",
    "                \"lep_eta\", \"lep_phi\", \"lep_charge\", \"lep_type\", \"met_et\", \"met_phi\", \"SumWeights\",\n",
    "                \"XSection\", \"jet_pt\", \"jet_MV2c10\", \"jet_n\", \"jet_eta\", \"jet_phi\", \"jet_E\",\n",
    "                \"lep_type\", \"lep_E\", \"eventNumber\"\n",
    "            ],\n",
    "            library=\"ak\",  # Choose output type as awkward array\n",
    "            entry_start=int(numevents * fraction * start_entry),\n",
    "            entry_stop=numevents * fraction * (start_entry + 1)\n",
    "            ):\n",
    "\n",
    "            nIn = len(data) # number of events in this batch\n",
    "\n",
    "            # Check triggerE, triggerM  conditions\n",
    "            data = data[cut_trig(data.trigE,data.trigM)]\n",
    "\n",
    "            # Require exactly one lepton\n",
    "            data = data[one_lep(data.lep_n)]\n",
    "\n",
    "            # cut on lepton lep_pt\n",
    "            data = data[ak.flatten(cut_lep_pt(data.lep_pt))]\n",
    "\n",
    "            # Cut on missing transverse energy met_et\n",
    "            data = data[cut_met_et(data.met_et)]\n",
    "\n",
    "            # Cut on W boson transverse mass\n",
    "            W_mt_data = cut_W_mt(data.lep_pt, data.lep_phi, data.met_et, data.met_phi)\n",
    "\n",
    "            data['W_mass'] = ak.flatten(W_mt_data[0])\n",
    "\n",
    "            data = data[ak.flatten(W_mt_data[1])]\n",
    "\n",
    "            # Check Njet and Nbjet  conditions\n",
    "            jets_data = cut_Njet_and_Nbjet(data.jet_pt,data.jet_MV2c10)\n",
    "\n",
    "            data['q_jets'] = jets_data[1]\n",
    "\n",
    "            data['b_jets'] = jets_data[2]\n",
    "\n",
    "            data['pt_jets'] = jets_data[3]\n",
    "\n",
    "            data = data[jets_data[0]]\n",
    "\n",
    "            if 'data' not in sample: # only do this for Monte Carlo simulation files\n",
    "                # multiply all Monte Carlo weights and scale factors together to give total weight\n",
    "                data['total_weight'] = calc_weight(data)\n",
    "\n",
    "            mtop_data = mtop(data.jet_pt ,data.jet_E ,data.jet_eta ,data.jet_phi ,data.jet_MV2c10 ,data.lep_pt, data.lep_eta ,data.lep_phi, data.lep_E, data.met_et, data.met_phi)\n",
    "\n",
    "            data['mtop'] = mtop_data[0]\n",
    "\n",
    "            data['mtop_1'] = mtop_data[1]\n",
    "\n",
    "            data['mtop_2'] = mtop_data[2]\n",
    "\n",
    "            nOut = len(data) # number of events passing cuts in this batch\n",
    "            data_all.append(data) # append array from this batch\n",
    "            elapsed = time.time() - start # time taken to process\n",
    "            print(\"\\t\\t nIn: \"+str(nIn)+\",\\t nOut: \\t\"+str(nOut)+\"\\t in \"+str(round(elapsed,1))+\"s\") # events before and after\n",
    "\n",
    "    return ak.concatenate(data_all) # return array containing events passing all cuts\n",
    "\n",
    "\n",
    "def get_data_from_files(start, local):\n",
    "    \"\"\"\n",
    "    Retrieves data from files and returns a dictionary of awkward arrays.\n",
    "\n",
    "    Args:\n",
    "        start (int): The starting point for data retrieval.\n",
    "        local (int): Flag indicating whether to use local files (1) or web URLs (0).\n",
    "\n",
    "    Returns:  dict: A dictionary containing concatenated awkward arrays for different samples.\n",
    "    \"\"\"\n",
    "    data = {}  # Define an empty dictionary to hold awkward arrays\n",
    "    MC_weight = []\n",
    "    BG_MC_weight = []\n",
    "\n",
    "    for s in samples:  # Loop over samples\n",
    "        print(f\"Processing {s} samples\")  # Print which sample is being processed\n",
    "        frames = []  # Define an empty list to hold data\n",
    "\n",
    "        for val in samples[s][\"list\"]:  # Loop over each file\n",
    "            if local == 1:\n",
    "                tuple_path, prefix = \"\", \"\"\n",
    "                fileString = f\"{tuple_path}{prefix}{val}.1lep.root\"  # File name to open\n",
    "                frames.append(read_file(fileString, val, start))  # Append array returned from read_file\n",
    "            else:\n",
    "                tuple_path = \"https://atlas-opendata.web.cern.ch/atlas-opendata/samples/2020/1lep/\"\n",
    "                if s == \"data\":\n",
    "                    prefix = \"Data/\"\n",
    "                elif s != \"data\":\n",
    "                    prefix = \"MC/\"\n",
    "\n",
    "                fileString = f\"{tuple_path}{prefix}{val}.1lep.root\"  # File name to open\n",
    "                frames.append(read_file(fileString, val, start))  # Append array returned from read_file\n",
    "\n",
    "        data[s] = ak.concatenate(frames)  # Dictionary entry is concatenated awkward arrays\n",
    "\n",
    "    return data  # Return the dictionary of awkward arrays\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703617b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Lists for the main analysis\n",
    "met_et_list = []       # Missing transverse energy\n",
    "Nbjet_list = []        # Number of b-jets\n",
    "Njet_list = []         # Number of jets\n",
    "MV2c10 = []            # b-tagging discriminant value\n",
    "pt = []                # Transverse momentum\n",
    "mW = []                # W boson mass\n",
    "Weight = []            # Event weight\n",
    "mtop_list = []         # Top quark mass\n",
    "mtop2_list = []        # Second top quark mass\n",
    "mtop3_list = []        # Third top quark mass\n",
    "\n",
    "# Lists for Monte Carlo (MC) simulated data\n",
    "met_et_list_MC = []    # Missing transverse energy in MC data\n",
    "Nbjet_list_MC = []     # Number of b-jets in MC data\n",
    "Njet_list_MC = []      # Number of jets in MC data\n",
    "pt_MC = []             # Transverse momentum in MC data\n",
    "mW_MC = []             # W boson mass in MC data\n",
    "Weight_MC = []         # Event weight in MC data\n",
    "mtop_list_MC = []      # Top quark mass in MC data\n",
    "mtop2_list_MC = []     # Second top quark mass in MC data\n",
    "mtop3_list_MC = []     # Third top quark mass in MC data\n",
    "\n",
    "# Lists for dilepton data\n",
    "met_et_list_Di = []    # Missing transverse energy in dilepton data\n",
    "Nbjet_list_Di = []     # Number of b-jets in dilepton data\n",
    "Njet_list_Di = []      # Number of jets in dilepton data\n",
    "pt_Di = []             # Transverse momentum in dilepton data\n",
    "mW_Di = []             # W boson mass in dilepton data\n",
    "Weight_Di = []         # Event weight in dilepton data\n",
    "mtop_list_Di = []      # Top quark mass in dilepton data\n",
    "mtop2_list_Di = []     # Second top quark mass in dilepton data\n",
    "mtop3_list_Di = []     # Third top quark mass in dilepton data\n",
    "\n",
    "# Lists for single top data\n",
    "met_et_list_ST = []    # Missing transverse energy in single top data\n",
    "Nbjet_list_ST = []     # Number of b-jets in single top data\n",
    "Njet_list_ST = []      # Number of jets in single top data\n",
    "pt_ST = []             # Transverse momentum in single top data\n",
    "mW_ST = []             # W boson mass in single top data\n",
    "Weight_ST = []         # Event weight in single top data\n",
    "mtop_list_ST = []      # Top quark mass in single top data\n",
    "mtop2_list_ST = []     # Second top quark mass in single top data\n",
    "mtop3_list_ST = []     # Third top quark mass in single top data\n",
    "\n",
    "number_of_runs =  1  # reduce this is if you want the code to run quicker (1 - 10)\n",
    "\n",
    "local_or_online = 0 # process all files 0 for web, 1 for local\n",
    "\n",
    "for i in range(number_of_runs):\n",
    "    fraction = 0.5\n",
    "    start = time.time()  # Time at the start of the whole processing\n",
    "\n",
    "    # Get data from files\n",
    "    list_tem = get_data_from_files(i, local_or_online)\n",
    "    data = list_tem\n",
    "\n",
    "    # Process data for \"data\" sample\n",
    "    data_type = \"data\"\n",
    "    met_et_list.append(data[data_type]['met_et'] * MeV2GeV)\n",
    "    Njet_list.append(data[data_type]['q_jets'])\n",
    "    Nbjet_list.append(data[data_type]['b_jets'])\n",
    "    pt.append(data[data_type]['pt_jets'])\n",
    "    mW.append(data[data_type]['W_mass'])\n",
    "    mtop_list.append(data[data_type]['mtop'])\n",
    "    mtop2_list.append(data[data_type]['mtop_1'])\n",
    "    mtop3_list.append(data[data_type]['mtop_2'])\n",
    "\n",
    "    # Process data for \"MC\" sample\n",
    "    data_type = \"MC\"\n",
    "    Weight_MC.append(data[data_type]['total_weight'])\n",
    "    met_et_list_MC.append(data[data_type]['met_et'] * MeV2GeV)\n",
    "    Njet_list_MC.append(data[data_type]['q_jets'])\n",
    "    Nbjet_list_MC.append(data[data_type]['b_jets'])\n",
    "    pt_MC.append(data[data_type]['pt_jets'])\n",
    "    mW_MC.append(data[data_type]['W_mass'])\n",
    "    mtop_list_MC.append(data[data_type]['mtop'])\n",
    "    mtop2_list_MC.append(data[data_type]['mtop_1'])\n",
    "    mtop3_list_MC.append(data[data_type]['mtop_2'])\n",
    "\n",
    "    # Process data for \"Single top\" sample\n",
    "    data_type = \"Single top\"\n",
    "    Weight_ST.append(data[data_type]['total_weight'])\n",
    "    met_et_list_ST.append(data[data_type]['met_et'] * MeV2GeV)\n",
    "    Njet_list_ST.append(data[data_type]['q_jets'])\n",
    "    Nbjet_list_ST.append(data[data_type]['b_jets'])\n",
    "    mW_ST.append(data[data_type]['W_mass'])\n",
    "    pt_ST.append(data[data_type]['pt_jets'])\n",
    "    mtop_list_ST.append(data[data_type]['mtop'])\n",
    "    mtop2_list_ST.append(data[data_type]['mtop_1'])\n",
    "    mtop3_list_ST.append(data[data_type]['mtop_2'])\n",
    "\n",
    "    # Process data for \"Diboson\" sample\n",
    "    data_type = \"Diboson\"\n",
    "    Weight_Di.append(data[data_type]['total_weight'])\n",
    "    met_et_list_Di.append(data[data_type]['met_et'] * MeV2GeV)\n",
    "    Njet_list_Di.append(data[data_type]['q_jets'])\n",
    "    Nbjet_list_Di.append(data[data_type]['b_jets'])\n",
    "    mW_Di.append(data[data_type]['W_mass'])\n",
    "    pt_Di.append(data[data_type]['pt_jets'])\n",
    "    mtop_list_Di.append(data[data_type]['mtop'])\n",
    "    mtop2_list_Di.append(data[data_type]['mtop_1'])\n",
    "    mtop3_list_Di.append(data[data_type]['mtop_2'])\n",
    "\n",
    "    elapsed = time.time() - start # time after whole processing\n",
    "    print(\"Time taken: \"+str(round(elapsed/60,1))+\"min\", f\"i = {i+1}\",\"\\n\") # print total time taken to process every file\n",
    "\n",
    "    del(list_tem)\n",
    "    del(data)\n",
    "\n",
    "# Flatten the lists for easier analysis\n",
    "mtop_list = ak.flatten(mtop_list)\n",
    "mtop2_list = ak.flatten(mtop2_list)\n",
    "mtop3_list = ak.flatten(mtop3_list)\n",
    "met_et_list = ak.flatten(met_et_list)\n",
    "Njet_list = ak.flatten(Njet_list)\n",
    "Nbjet_list = ak.flatten(Nbjet_list)\n",
    "pt = ak.flatten(pt)\n",
    "mW = ak.flatten(mW)\n",
    "\n",
    "# Flatten MC-related lists\n",
    "Weight_MC = ak.flatten(Weight_MC)\n",
    "mtop_list_MC = ak.flatten(mtop_list_MC)\n",
    "mtop2_list_MC = ak.flatten(mtop2_list_MC)\n",
    "mtop3_list_MC = ak.flatten(mtop3_list_MC)\n",
    "met_et_list_MC = ak.flatten(met_et_list_MC)\n",
    "Njet_list_MC = ak.flatten(Njet_list_MC)\n",
    "Nbjet_list_MC = ak.flatten(Nbjet_list_MC)\n",
    "mW_MC = ak.flatten(mW_MC)\n",
    "pt_MC = ak.flatten(pt_MC)\n",
    "\n",
    "# Flatten Single top-related lists\n",
    "Weight_ST = ak.flatten(Weight_ST)\n",
    "mtop_list_ST = ak.flatten(mtop_list_ST)\n",
    "mtop2_list_ST = ak.flatten(mtop2_list_ST)\n",
    "mtop3_list_ST = ak.flatten(mtop3_list_ST)\n",
    "met_et_list_ST = ak.flatten(met_et_list_ST)\n",
    "Njet_list_ST = ak.flatten(Njet_list_ST)\n",
    "Nbjet_list_ST = ak.flatten(Nbjet_list_ST)\n",
    "mW_ST = ak.flatten(mW_ST)\n",
    "pt_ST = ak.flatten(pt_ST)\n",
    "\n",
    "# Flatten Diboson-related lists\n",
    "Weight_Di = ak.flatten(Weight_Di)\n",
    "mtop_list_Di = ak.flatten(mtop_list_Di)\n",
    "mtop2_list_Di = ak.flatten(mtop2_list_Di)\n",
    "mtop3_list_Di = ak.flatten(mtop3_list_Di)\n",
    "met_et_list_Di = ak.flatten(met_et_list_Di)\n",
    "Njet_list_Di = ak.flatten(Njet_list_Di)\n",
    "Nbjet_list_Di = ak.flatten(Nbjet_list_Di)\n",
    "mW_Di = ak.flatten(mW_Di)\n",
    "pt_Di = ak.flatten(pt_Di)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9a3eeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine mtop2 and mtop3 lists \n",
    "mtop2 = ak.flatten([mtop2_list, mtop3_list])\n",
    "weights_data = ak.Array([1/2] * len(mtop2))\n",
    "\n",
    "# Combine MC-related lists\n",
    "mtop2_MC = ak.flatten([mtop2_list_MC, mtop3_list_MC])\n",
    "weights_MC = ak.flatten([Weight_MC, Weight_MC]) / 2\n",
    "\n",
    "# Combine Single top-related lists\n",
    "mtop2_ST = ak.flatten([mtop2_list_ST, mtop3_list_ST])\n",
    "weights_ST = ak.flatten([Weight_ST, Weight_ST]) / 2\n",
    "\n",
    "# Combine Diboson-related lists\n",
    "mtop2_Di = ak.flatten([mtop2_list_Di, mtop3_list_Di])\n",
    "weights_Di = ak.flatten([Weight_Di, Weight_Di]) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d484d41b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(data, data_MC, MC_Weight, data_Di, Di_Weight, data_ST, ST_Weight, \n",
    "              x_axis_label, weight_for_data, weight_data):\n",
    "    \"\"\"\n",
    "    Plot histogram data with Monte Carlo simulations and calculate ratio plot.\n",
    "\n",
    "    Parameters:\n",
    "    -----------\n",
    "    data : array\n",
    "        The main data to be plotted.\n",
    "    data_MC, data_Di, data_ST : array\n",
    "        Monte Carlo, Diboson, and Single Top data respectively.\n",
    "    MC_Weight, Di_Weight, ST_Weight : array-like\n",
    "        Weights for the respective data sets.\n",
    "    x_axis_label : str\n",
    "        Label for the x-axis.\n",
    "    weight_for_data : bool\n",
    "        Flags for additional functionality.\n",
    "    weight_data : array\n",
    "        Weights for the main data.\n",
    "\n",
    "    Returns:\n",
    "    --------\n",
    "    None\n",
    "    \"\"\"\n",
    "\n",
    "    # Define plot parameters\n",
    "    xmin, xmax, step_size = 100, 250, 3\n",
    "\n",
    "    # Define MC data sets and their properties\n",
    "    datasets = [\n",
    "        {'data': data_Di, 'weights': Di_Weight, 'color': 'blue', 'label': r'Diboson'},\n",
    "        {'data': data_ST, 'weights': ST_Weight, 'color': 'cyan', 'label': r'Single top'},\n",
    "        {'data': data_MC, 'weights': MC_Weight, 'color': 'orange', 'label': r'$t\\bar{t}$'}\n",
    "    ]\n",
    "\n",
    "    # Create bin edges and centers\n",
    "    bin_edges = np.arange(xmin, xmax + step_size, step_size)\n",
    "    bin_centres = np.arange(xmin + step_size/2, xmax + step_size/2, step_size)\n",
    "\n",
    "    # Histogram the data and weights for the data\n",
    "    if weight_for_data:\n",
    "        data_x, _ = np.histogram(ak.to_numpy(data), bins=bin_edges, weights=weight_data)\n",
    "    else:\n",
    "        data_x, _ = np.histogram(ak.to_numpy(data), bins=bin_edges)\n",
    "\n",
    "    data_x_errors = np.sqrt(data_x)  # statistical error on the data\n",
    "\n",
    "    # Create main plot and residual subplot\n",
    "    fig, (main_axes, residual_axes) = plt.subplots(2, 1, figsize=(7, 6), gridspec_kw={'height_ratios': [3, 1]}, sharex=True)\n",
    "\n",
    "    # Plot data with error bars\n",
    "    main_axes.errorbar(x=bin_centres, y=data_x, yerr=data_x_errors,\n",
    "                       fmt='ko', label='Data')\n",
    "\n",
    "    # Plot the Monte Carlo bars\n",
    "    mc_heights = main_axes.hist([d['data'] for d in datasets], bins=bin_edges,\n",
    "                                weights=[d['weights'] for d in datasets], stacked=True,\n",
    "                                color=[d['color'] for d in datasets], label=[d['label'] for d in datasets])\n",
    "\n",
    "    mc_x_tot = mc_heights[0]  # Stacked background MC y-axis value\n",
    "\n",
    "    # Calculate MC statistical uncertainty: sqrt(sum w^2)\n",
    "    mc_x_err = np.sqrt(np.histogram(np.hstack([d['data'] for d in datasets]), bins=bin_edges,\n",
    "                                    weights=np.hstack([d['weights'] for d in datasets])**2)[0])\n",
    "\n",
    "    # Plot the statistical uncertainty\n",
    "    main_axes.bar(bin_centres, 2*mc_x_err, alpha=0.5, bottom=mc_x_tot[2]-mc_x_err,\n",
    "                  color='none', hatch=\"////\", width=step_size, label='Stat. Unc.')\n",
    "\n",
    "    # Set up main axes\n",
    "    main_axes.set_xlim(left=xmin, right=xmax)\n",
    "    \n",
    "    # Add headspace to the plot\n",
    "    ymax = max(np.max(data_x), np.max(np.sum(mc_heights[0], axis=0)))\n",
    "    main_axes.set_ylim(0, ymax * 1.4)  # Add 40% headspace\n",
    "    \n",
    "    main_axes.xaxis.set_minor_locator(AutoMinorLocator())\n",
    "    main_axes.tick_params(which='both', direction='in', top=True, right=True)\n",
    "    main_axes.set_ylabel('Events', y=1, horizontalalignment='right')\n",
    "    main_axes.yaxis.set_minor_locator(AutoMinorLocator())\n",
    "\n",
    "    # Add text to the plot\n",
    "    main_axes.text(0.05, 0.93, 'ATLAS Open Data', transform=main_axes.transAxes, fontsize=13)\n",
    "    main_axes.text(0.05, 0.88, 'for education', transform=main_axes.transAxes, style='italic', fontsize=8)\n",
    "    main_axes.text(0.05, 0.82, r'$\\sqrt{s}$=13 TeV, 10 fb$^{-1}$', transform=main_axes.transAxes)\n",
    "    main_axes.text(0.05, 0.76, r'$t\\bar{t} \\rightarrow \\ell v b\\bar{b} q\\bar{q}$', transform=main_axes.transAxes)\n",
    "\n",
    "    main_axes.legend(frameon=False)\n",
    "\n",
    "    # Calculate and plot residuals\n",
    "    ratio = data_x / np.sum(mc_heights[0], axis=0)\n",
    "    residual_axes.errorbar(bin_centres, ratio, fmt='ko')\n",
    "    residual_axes.axhline(1, color='r', linestyle='--')\n",
    "    residual_axes.set_xlabel(x_axis_label, fontsize=13, x=1, horizontalalignment='right')\n",
    "    residual_axes.set_ylabel('Ratio (Data/MC)')\n",
    "    residual_axes.xaxis.set_minor_locator(AutoMinorLocator())\n",
    "    residual_axes.yaxis.set_minor_locator(AutoMinorLocator())\n",
    "    residual_axes.tick_params(which='both', direction='in', top=True, right=True)\n",
    "\n",
    "    # Adjust layout\n",
    "    fig.tight_layout()\n",
    "    fig.subplots_adjust(hspace=0.05)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561a5c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the trijet mass distribution (m_jjj)\n",
    "plot_data(mtop_list,        # Main data: list of trijet masses\n",
    "          mtop_list_MC,     # Monte Carlo data for ttbar\n",
    "          Weight_MC,        # Weights for Monte Carlo data\n",
    "          mtop_list_Di,     # Diboson background data\n",
    "          Weight_Di,        # Weights for Diboson data\n",
    "          mtop_list_ST,     # Single Top background data\n",
    "          Weight_ST,        # Weights for Single Top data\n",
    "          r\"$\\mathrm{m_{jjj}} [GeV]$\",  # x-axis label: trijet mass in GeV\n",
    "          False,            # Don't use weights for the main data\n",
    "          [])               # Empty list for data weights (not used)\n",
    "\n",
    "# Plot the lepton-neutrino-b-jet mass distribution (m_lvb)\n",
    "plot_data(mtop2,            # Main data: list of lepton-neutrino-b-jet masses\n",
    "          mtop2_MC,         # Monte Carlo data for ttbar\n",
    "          weights_MC,       # Weights for Monte Carlo data\n",
    "          mtop2_Di,         # Diboson background data\n",
    "          weights_Di,       # Weights for Diboson data\n",
    "          mtop2_ST,         # Single Top background data\n",
    "          weights_ST,       # Weights for Single Top data\n",
    "          r\"$\\mathrm{m_{lvb}} [GeV]$\",  # x-axis label: lepton-neutrino-b-jet mass in GeV\n",
    "          True,             # Use weights for the main data\n",
    "          weights_data)     # Weights for the main data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a7f873",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
